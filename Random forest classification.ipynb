{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest classification\n",
    "## Importing the libraries\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('card_transdata.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[57.87785658  0.31114001  1.94593998 ...  1.          0.\n",
      "   0.        ]\n",
      " [10.8299427   0.1755915   1.29421881 ...  0.          0.\n",
      "   0.        ]\n",
      " [ 5.09107949  0.80515259  0.42771456 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [ 2.91485699  1.47268669  0.21807549 ...  1.          0.\n",
      "   1.        ]\n",
      " [ 4.25872939  0.24202337  0.47582206 ...  0.          0.\n",
      "   1.        ]\n",
      " [58.10812496  0.31811012  0.38691985 ...  1.          0.\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.628792</td>\n",
       "      <td>5.036519</td>\n",
       "      <td>1.824182</td>\n",
       "      <td>0.881536</td>\n",
       "      <td>0.350399</td>\n",
       "      <td>0.100608</td>\n",
       "      <td>0.650552</td>\n",
       "      <td>0.087403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>65.390784</td>\n",
       "      <td>25.843093</td>\n",
       "      <td>2.799589</td>\n",
       "      <td>0.323157</td>\n",
       "      <td>0.477095</td>\n",
       "      <td>0.300809</td>\n",
       "      <td>0.476796</td>\n",
       "      <td>0.282425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.004874</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.878008</td>\n",
       "      <td>0.296671</td>\n",
       "      <td>0.475673</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.967760</td>\n",
       "      <td>0.998650</td>\n",
       "      <td>0.997717</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.743985</td>\n",
       "      <td>3.355748</td>\n",
       "      <td>2.096370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10632.723672</td>\n",
       "      <td>11851.104565</td>\n",
       "      <td>267.802942</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       distance_from_home  distance_from_last_transaction  \\\n",
       "count      1000000.000000                  1000000.000000   \n",
       "mean            26.628792                        5.036519   \n",
       "std             65.390784                       25.843093   \n",
       "min              0.004874                        0.000118   \n",
       "25%              3.878008                        0.296671   \n",
       "50%              9.967760                        0.998650   \n",
       "75%             25.743985                        3.355748   \n",
       "max          10632.723672                    11851.104565   \n",
       "\n",
       "       ratio_to_median_purchase_price  repeat_retailer       used_chip  \\\n",
       "count                  1000000.000000   1000000.000000  1000000.000000   \n",
       "mean                         1.824182         0.881536        0.350399   \n",
       "std                          2.799589         0.323157        0.477095   \n",
       "min                          0.004399         0.000000        0.000000   \n",
       "25%                          0.475673         1.000000        0.000000   \n",
       "50%                          0.997717         1.000000        0.000000   \n",
       "75%                          2.096370         1.000000        1.000000   \n",
       "max                        267.802942         1.000000        1.000000   \n",
       "\n",
       "       used_pin_number    online_order           fraud  \n",
       "count   1000000.000000  1000000.000000  1000000.000000  \n",
       "mean          0.100608        0.650552        0.087403  \n",
       "std           0.300809        0.476796        0.282425  \n",
       "min           0.000000        0.000000        0.000000  \n",
       "25%           0.000000        0.000000        0.000000  \n",
       "50%           0.000000        1.000000        0.000000  \n",
       "75%           0.000000        1.000000        0.000000  \n",
       "max           1.000000        1.000000        1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                          Non-Null Count    Dtype  \n",
      "---  ------                          --------------    -----  \n",
      " 0   distance_from_home              1000000 non-null  float64\n",
      " 1   distance_from_last_transaction  1000000 non-null  float64\n",
      " 2   ratio_to_median_purchase_price  1000000 non-null  float64\n",
      " 3   repeat_retailer                 1000000 non-null  float64\n",
      " 4   used_chip                       1000000 non-null  float64\n",
      " 5   used_pin_number                 1000000 non-null  float64\n",
      " 6   online_order                    1000000 non-null  float64\n",
      " 7   fraud                           1000000 non-null  float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 61.0 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_value = float(\"Nan\")\n",
    "#missing values are represented with '9' in this dataset\n",
    "dataset.replace(to_replace =9 ,value = new_value, inplace= True)\n",
    "dataset = dataset.dropna()\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find and Remove Duplicate rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.duplicated().sum()\n",
    "dataset.drop_duplicates(inplace=True)\n",
    "#size after removing duplicates\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.58733764e+00 4.25548683e-01 2.11492301e-01 ... 0.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [1.87274416e+01 1.51142880e-02 1.36290579e+00 ... 0.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [2.83393468e+01 3.99962434e-01 4.91858862e-01 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " ...\n",
      " [2.68070835e+01 4.40967803e+00 4.84272835e-01 ... 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00]\n",
      " [1.21443426e+01 4.08443337e-02 1.79287662e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [4.93375070e+01 5.25678996e-01 3.22232714e+00 ... 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.66060786  0.10902654  4.30416756 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.79312666  1.55401696  0.73468389 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 1.44662928  1.06029302  0.62118212 ...  0.          0.\n",
      "   1.        ]\n",
      " ...\n",
      " [36.8792349   1.02906813  0.09171728 ...  1.          0.\n",
      "   0.        ]\n",
      " [ 3.73082529  0.14468908  0.86922081 ...  0.          0.\n",
      "   1.        ]\n",
      " [ 0.64275956  0.05048547  2.215808   ...  0.          0.\n",
      "   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.69867284e-01 -1.69775265e-01 -5.75465065e-01 ... -7.34373613e-01\n",
      "   2.98724857e+00  7.32342041e-01]\n",
      " [-1.21861004e-01 -1.84870184e-01 -1.64475032e-01 ... -7.34373613e-01\n",
      "   2.98724857e+00  7.32342041e-01]\n",
      " [ 2.58340077e-02 -1.70716274e-01 -4.75389929e-01 ... -7.34373613e-01\n",
      "  -3.34756207e-01  7.32342041e-01]\n",
      " ...\n",
      " [ 2.28949297e-03 -2.32473189e-02 -4.78097715e-01 ... -7.34373613e-01\n",
      "   2.98724857e+00 -1.36548217e+00]\n",
      " [-2.23015860e-01 -1.83923887e-01 -1.09995663e-02 ... -7.34373613e-01\n",
      "  -3.34756207e-01  7.32342041e-01]\n",
      " [ 3.48488410e-01 -1.66092682e-01  4.99234090e-01 ...  1.36170470e+00\n",
      "  -3.34756207e-01 -1.36548217e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.35337558 -0.18141629  0.88539044 ... -0.73437361 -0.33475621\n",
      "   0.73234204]\n",
      " [-0.39743685 -0.12827256 -0.38871501 ... -0.73437361 -0.33475621\n",
      "   0.73234204]\n",
      " [-0.38739523 -0.1464307  -0.42922878 ... -0.73437361 -0.33475621\n",
      "   0.73234204]\n",
      " ...\n",
      " [ 0.15705658 -0.14757908 -0.61821803 ...  1.3617047  -0.33475621\n",
      "  -1.36548217]\n",
      " [-0.35229663 -0.18010469 -0.34069288 ... -0.73437361 -0.33475621\n",
      "   0.73234204]\n",
      " [-0.39974736 -0.18356931  0.13996321 ... -0.73437361 -0.33475621\n",
      "   0.73234204]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Random forest classification model on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting a new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[228273      0]\n",
      " [     3  21724]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.999988"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14958d3aee5f1cad06795f787e54b96185c25fb40dfec723a5be941f3a531b8c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
